---
title: 更炫酷的反演魔术
---

容斥的更深刻解释。

# 容斥是什么

显然它指的已经不是子集反演了……事实上，容斥的定义在 OI 圈是有些混乱的。

- 子集反演当然是容斥。
- 莫比乌斯反演、二项式反演也应是容斥。
- min-max 容斥名字里就带着“容斥”二字。
- - 那么问题来了：
  - 如果反演都是容斥，那么斯特林反演，拉格朗日反演算不算容斥？
  - 矩阵树定理可以用容斥的思想解释，那它算不算容斥？
  - 对合法和容斥的思路完全不同，可是为什么却有很多人说它是容斥？
  - 事实上我也不认为 min-max 容斥是容斥。

之后我们会给出本文讨论的容斥的具体定义。在此之前我们先来发明一些容斥找找感觉。

# 论如何发明容斥

## 例子：错排问题

考虑所有置换构成的组合类 $\mathcal P$。构造 $\mathcal Q$ 是这样的一个组合类，其中元素都是置换，而我们还可以标记一些不动点。也就是说，同一个置换但是一个不动点标不标记是两个在 $\mathcal Q$ 中的对象。$\mathcal Q$ 是容易计数的：标记的点必须守序（标号为 $1,2,3,...$，毕竟它们是不动点）而其他点不必，从而有
$$
\mathcal Q=\text{SET}(\mathcal Z)\star\mathcal P
$$
我们在 GF 中用一个新的变元 $u$ 指出 $\mathcal Q$ 中元素的标记点的数量：
$$
Q(u,z)=\dfrac{e^{uz}}{1-z}
$$
我们还是用 $u$ 指出 $\mathcal P$ 中**不动点**的数量，显然 $\mathcal P$ 中的不动点（一个 $u$ 的贡献）都可以选择标记和不被标记，即贡献 $u$ 或贡献 $1$。从而通过这个 $u\to u+1$ 立即得到
$$
Q(u,z)=P(u+1,z)
$$

$$
P(0,z)=\dfrac{e^{-z}}{1-z}
$$

问题得到解决。事实上我们可以直接扩展到一般的二项式反演。

从这个问题中看不大出容斥符号化的优越性。来个更劲爆的？

## 例子：莫比乌斯反演

我们有
$$
f_n=\sum_{d|n}g_d
$$
则 $g=?$

首先明确，一个整数可以看成它的质因子分解序列，比如 $12=(2,1,0,0...)$ 我们把整个序列作为它的大小函数。单个元素的 GF 就是 $x_1^{e_1}x_2^{e_2}...$，比如 $T(12;x_1,x_2,...)=x_1^2x_2$。容易验证这个 GF 在“笛卡尔积”下积性。则我们有
$$
\mathcal F=\N\times\mathcal G
$$
考虑 $\N$ 的 GF，它当然是 $\prod_{i=1}^{\infty}\dfrac{1}{1-x_i}$。那么我们甚至不需要构造新的 $\mathcal Q$（事实上 $\mathcal F$ 就是我们想要的 $\mathcal Q$）就直接可以得到 $G=F\prod_{i=1}^{\infty}(1-x_i)$。而后面那个东西则是我们熟知的莫比乌斯函数。

这个例子不是很恰当，因为其实我们只是重新发明了狄利克雷生成函数而已。来个更劲爆的？

## 例子：min-max 容斥

考虑 GF $T(t)=\max t \cdot x_1^{c_1}x_2^{c_2}...x_n^{c_n}$。其中 $c_i=[i\in t]$。元素已经从小到大排序。容易写出整个组合类的 GF 为
$$
\sum_{i=1}^n v_ix_i\prod_{j<i} (1+x_j)
$$
取 $\forall i,x_i=-1$ 立即得到 min-max 容斥。

当然我们更熟悉的 min-max 容斥其实是在期望上的，实际上它很好证明。因为在任意一个基本事件上都有 min-max 容斥，再根据期望的线性便立即得证。

来个更劲爆的？

## 例子：扩展 min-max 容斥

显然上面的式子爆炸了。根本原因在于它的构造依赖于 $0^{x}=[x=0]$。那么我们代入 $x_i=\begin{cases}0&(i<k)\\-1&(i\ge k)\end{cases}$ 不就好了吗！（智将）

其实这道理也是有的，但是我们更希望各 $x_i$ 平等（不然可能会很难受。关键在于我们往往分辨不出是否有 $i<k$，能分辨出的话也没必要容斥）。显然这时 $x_i$ 取任何值都不能满足我们的要求，所以我们考虑给 $x^i$ 自带一个权值 $f(i)$。比如原来就是 $f(i)=(-1)^i$。那么这个权值要满足
$$
\sum_{j=0}^{i-1}{i-1\choose j}f(j+1)=0\quad(i\neq k)\\
\sum_{j=0}^{k-1}{k-1\choose j}f(j+1)\neq 0
$$
草，这就没意思了，直接二项式反演即可。不过可以看到的是，符号化方法为我们指明了道路，还提供了一个对所谓“容斥系数”的高妙解释。

## 例子：斯特林反演

这是一个清新的一维问题。

> 现有一排 $n$ 个格子，每个格子皆可涂成 $k$ 种颜色之一。
>
> 给定集合 $S$，定义一个染色**合法**当且仅当：对于任意格子，记和它颜色相同的格子有 $x$ 个（包括自身），必有 $x\in S$。
>
> 求有多少合法的染色方案。

哦，这不是思博题吗！记 $F=\sum_{i\in S}x^i$，那么
$$
ans=\left[\dfrac{x^n}{n!}\right](1+F)^k
$$
当然，的确是这样。但还有如下的**另外一种思路**：

考虑所有 $1\sim n$ 的**划分**：划分是一串集合的**无序列表** $L=\{S_1,...,S_{\ell}\}$，其中的集合两两不交且并恰为 $\{1,...,n\}$。

我们希望有一组奥妙重重的贴在所有划分上的容斥系数 $c$，它满足如下性质：

- $ans=\sum_{L}c(L)k^{|L|}$，其中 $|L|$ 是 $L$ 的长度，即上文的 $\ell$。
- $c$ 由一组隐藏的系数 $\hat c$ 以如下方式生成：$c(L)=\prod_{i=1}^{|L|}\hat c(|S_i|)$。
- 而且 $\hat c$ 与 $n,k$ 无关。

我们指出，上面的条件已经直接地把 $\hat c$ 的取值可能性缩小到了最多一种。具体来说，取 $k=1$，则显然 $ans=[n\in S\lor n=0]$。又注意到根据划分和集合是无序列表的关系，那么直接有
$$
\sum_Lc(L)=\left[\dfrac{x^n}{n!}\right]\text{exp}\left(\sum_i\hat c(i)\dfrac{x^i}{i!}\right)
$$
于是，
$$
\sum_{i}\hat c(i)\dfrac{x^i}{i!}=\ln(1+F)
$$
然后我们只需要指出这组 $\hat c$ 真的是满足第一个条件的。有
$$
\text{exp}(k\ln(1+F))=ans=(1+F)^k
$$
这就得证了。所以说，上面的容斥系数的确是正确的。不过它也只是正确而已，这个问题太容易用别的方法得出解，于是难以看出其优越性。它的优越性得等到下一个问题。

> 注意到 $ans$ 还可表示为
> $$
> \sum_{L}k^{|L|}\prod_{i=1}^{|L|}\hat c(S_i)=ans=\sum_{L}k^{\underline{|L|}}\prod_{i=1}^{|L|}[|S_i|\in S]
> $$
> 取 $S=\{1\}$，我们就证明了斯特林反演。

# 反演的笛卡尔积？

我们来考虑容斥的一些比较本质的特征。

现在有一个集合 $X$，其上有一个**偏序关系** $\le$。我们有两个函数 $f,g:X\rightarrow\mathbb R$，这两个函数 $f,g$ 有某种关系，具体来说：
$$
g(x)=\sum_{y\le x}f(y)
$$
我们当然可以用 $f$ 表示 $g$，这就是所谓的**反演**。
$$
f(x)=\sum_{y}c(x,y)g(y)
$$
对于子集反演，$X$ 就是所有 $\{1...n\}$ 的子集，偏序关系就是包含关系；二项式反演是子集反演的特殊情形；莫比乌斯反演是子集反演的一个小扩展。min-max 容斥只是玩了一点小数字花样，这里把它开除容斥籍。

“斯特林反演”的结构就完全不同了，此处 $X$ 变为所有 $\{1...n\}$ 的划分，而偏序关系变为“前者是否可以通过若干次合并操作变为后者”。

<center><div style="width:90%;margin:auto"><img src="https://xyix.gitee.io/images/exc-inc.png" style="width: 70%" alt=""></div></center>

## 例子：U 群把妹王

这是一个恐怖的二维问题。

> 现有 $n\times m$ 个格子，每个格子皆可涂成 $k$ 种颜色之一。
>
> 给定集合 $S,T$，定义一个染色**合法**当且仅当：
>
> - 对于任意一行，记和它图案相同的行有 $x$ 个（包括自身），必有 $x\in S$。
> - 对于任意一列，记和它图案相同的列有 $x$ 个（包括自身），必有 $x\in T$。
>
> 求有多少合法的染色方案。

$\hat c$ 还是如上定义，$\hat d$ 则是把 $S$ 换成了 $T$。我们来证明，
$$
ans=\sum_{L_1}\sum_{L_2}c(L_1)d(L_2)k^{|L_1||L_2|}
$$
这回我们根本无法用另一种方法数出 $ans$，之前的方法自然完蛋了。

